# Dataset manager

<!-- Badges -->
![Version](https://img.shields.io/github/v/tag/vncntprvst/dataset-manager?label=version&sort=semver)
![License](https://img.shields.io/badge/License-CC--BY--4.0-lightgrey.svg)
![Python](https://img.shields.io/badge/Python-3.11%2B-informational.svg)
![Status](https://img.shields.io/badge/status-alpha-orange.svg)
![Issues](https://img.shields.io/github/issues/vncntprvst/dataset-manager.svg)
![Last Commit](https://img.shields.io/github/last-commit/vncntprvst/dataset-manager.svg)
![Streamlit](https://img.shields.io/badge/built%20with-Streamlit-ff4b4b.svg)

A user interface that helps bundle data and metadata based on experimental types, while ensuring compatibility with NWB / DANDI archive submission requirements.

This project was created as part of the Team BRAIN Circuit Program (U19) NS137920:  
ðŸ”— [_High- and low-level computations for coordination of orofacial motor actions_](https://rhythm-n-rodents.github.io/)

## Overview

This application generates data collection templates and conversion scripts tailored to specific experimental types. Users select their experimental modalities, and the tool automatically creates spreadsheets with the appropriate metadata fields required for NWB file creation and DANDI archive submission, and then generates a script to convert the collected data into NWB format.

<img width="863" height="899" alt="image" src="https://github.com/user-attachments/assets/2ab91c40-3f54-4e5d-b9c3-fc4c368acaa7" />

### Workflow

1. Select experimental types relevant to your research
2. Create a dataset on a data repository (e.g., DANDI)
3. Generate and download your customized template as `.xlsx` or `.csv`. This interface helps researchers create standardized data collection templates that comply with NWB (Neurodata Without Borders) and DANDI (Distributed Archives for Neurophysiology Data Integration) standards.
4. Generate a conversion script to transform your collected data into NWB files.
5. Use the generated script to convert your data into NWB format, ensuring it meets the necessary standards for sharing and archiving. 

### Supported Experimental Types
- Electrophysiology â€“ Extracellular / Intracellular
- Behavior and physiological measurements
- Optical Physiology
- Stimulations
- Experimental metadata and notes

### Schema Validation

The application enforces data standards via two complementary schema layers:

1. DANDI metadata layer. We load the official `dandischema` (Pydantic models) or the JSON Schema it produces. This automatically gives us the full set of required and optional fields plus their data typesâ€”no manual duplication. (Reference: https://docs.dandiarchive.org)
2. NWB core layer. We rely on PyNWB to construct `NWBFile` objects. At minimum an NWB file must define: `session_description`, `identifier`, and `session_start_time`. The app can validate the resulting structure with PyNWBâ€™s builtâ€‘in validator and apply additional bestâ€‘practice checks using NWB Inspector.

With those definitions in place, the app generates a session-oriented spreadsheet template (one row per recording session) for you to complete.

### Usage
- Clone this repository.  
    `git clone https://github.com/vncntprvst/dataset-manager.git`
- Run the app:
    * Double-click `run_app.bat` (Windows) or run `./run_app.sh` (Mac/Linux) from the terminal.   
    You can also drag and drop a data folder onto the script icon.
    * Alternatively:
        If using [`uv`](https://docs.astral.sh/uv/getting-started/installation/) (recommended):  
        `uv run streamlit run app.py`

        or, if not using uv:  
            - Create a virtual environment (Python 3.9+)  
            - Install dependencies    
            `pip install -r requirements.txt`  
            - Activate environment, then `streamlit run app.py`

